{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-heather",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 Dialpad, Inc. (Shreekantha Nadig, Riqiang Wang)\n",
    "#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "twenty-catalog",
   "metadata": {},
   "outputs": [],
   "source": [
    "from espnet.asr.pytorch_backend.asr_init import load_trained_model\n",
    "from espnet.bin.asr_recog import get_parser\n",
    "from espnet.asr.asr_utils import parse_hypothesis\n",
    "from espnet.asr.asr_utils import get_model_conf\n",
    "import espnet.nets.pytorch_backend.lm.default as lm_pytorch\n",
    "from espnet.asr.asr_utils import torch_load\n",
    "import espnet.lm.pytorch_backend.extlm as extlm_pytorch\n",
    "from espnet.utils.deterministic_utils import set_deterministic_pytorch\n",
    "from espnet.transform.cmvn import CMVN\n",
    "import torchaudio\n",
    "import torch\n",
    "import numpy as np\n",
    "import resampy\n",
    "import math\n",
    "import kaldiio\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "import wave\n",
    "import array\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "played-yield",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmvn_stats_file = \"mucs_2021_models/b0/is21_challenge/data/task1/train_combined/cmvn_default.ark\"\n",
    "cmvn = CMVN(cmvn_stats_file, norm_vars=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-offset",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "equal-spirituality",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:reading model parameters from mucs_2021_models/b0/exp/train_enc_dec_multilingual_default_large/results/model.acc.best\n",
      "WARNING:root:Subsampling is not performed for vgg*. It is performed in max pooling layers at CNN.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "E2E(\n",
       "  (enc): Encoder(\n",
       "    (enc): ModuleList(\n",
       "      (0): VGG2L(\n",
       "        (conv1_1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv1_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (1): RNNP(\n",
       "        (birnn0): LSTM(2560, 1024, batch_first=True, bidirectional=True)\n",
       "        (bt0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "        (birnn1): LSTM(1024, 1024, batch_first=True, bidirectional=True)\n",
       "        (bt1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "        (birnn2): LSTM(1024, 1024, batch_first=True, bidirectional=True)\n",
       "        (bt2): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "        (birnn3): LSTM(1024, 1024, batch_first=True, bidirectional=True)\n",
       "        (bt3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "        (birnn4): LSTM(1024, 1024, batch_first=True, bidirectional=True)\n",
       "        (bt4): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "        (birnn5): LSTM(1024, 1024, batch_first=True, bidirectional=True)\n",
       "        (bt5): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ctc): CTC(\n",
       "    (ctc_lo): Linear(in_features=1024, out_features=304, bias=True)\n",
       "    (ctc_loss): CTCLoss()\n",
       "  )\n",
       "  (att): ModuleList(\n",
       "    (0): AttCovLoc(\n",
       "      (mlp_enc): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (mlp_dec): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "      (mlp_att): Linear(in_features=10, out_features=1024, bias=False)\n",
       "      (loc_conv): Conv2d(1, 10, kernel_size=(1, 201), stride=(1, 1), padding=(0, 100), bias=False)\n",
       "      (gvec): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (dec): Decoder(\n",
       "    (embed): Embedding(304, 1024)\n",
       "    (dropout_emb): Dropout(p=0.1, inplace=False)\n",
       "    (decoder): ModuleList(\n",
       "      (0): LSTMCell(2048, 1024)\n",
       "      (1): LSTMCell(1024, 1024)\n",
       "    )\n",
       "    (dropout_dec): ModuleList(\n",
       "      (0): Dropout(p=0.1, inplace=False)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (output): Linear(in_features=1024, out_features=304, bias=True)\n",
       "    (att): ModuleList(\n",
       "      (0): AttCovLoc(\n",
       "        (mlp_enc): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (mlp_dec): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (mlp_att): Linear(in_features=10, out_features=1024, bias=False)\n",
       "        (loc_conv): Conv2d(1, 10, kernel_size=(1, 201), stride=(1, 1), padding=(0, 100), bias=False)\n",
       "        (gvec): Linear(in_features=1024, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"mucs_2021_models/b0/exp/train_enc_dec_multilingual_default_large/results/model.acc.best\"\n",
    "decode_config = \"mucs_2021_models/b0/conf/decode.yaml\"\n",
    "model, train_args = load_trained_model(model_path)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-tourism",
   "metadata": {},
   "source": [
    "# Load RNNLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "northern-boxing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierWithState(\n",
       "  (lossfun): CrossEntropyLoss()\n",
       "  (predictor): RNNLM(\n",
       "    (embed): Embedding(304, 1024)\n",
       "    (rnn): ModuleList(\n",
       "      (0): LSTMCell(1024, 1024)\n",
       "      (1): LSTMCell(1024, 1024)\n",
       "    )\n",
       "    (dropout): ModuleList(\n",
       "      (0): Dropout(p=0.5, inplace=False)\n",
       "      (1): Dropout(p=0.5, inplace=False)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (lo): Linear(in_features=1024, out_features=304, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnnlm_path = \"mucs_2021_models/rnnlms/combined/rnnlm/rnnlm.model.best\"\n",
    "rnnlm_opts = f\"--rnnlm {rnnlm_path}\"\n",
    "rnnlm_args = get_model_conf(rnnlm_path)\n",
    "rnnlm = lm_pytorch.ClassifierWithState(\n",
    "    lm_pytorch.RNNLM(\n",
    "        len(rnnlm_args.char_list_dict),\n",
    "        rnnlm_args.layer,\n",
    "        rnnlm_args.unit,\n",
    "        getattr(rnnlm_args, \"embed_unit\", None),  # for backward compatibility\n",
    "    )\n",
    ")\n",
    "torch_load(rnnlm_path, rnnlm)\n",
    "rnnlm.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "lovely-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = get_parser()\n",
    "rnnlm_opts = \"\"\n",
    "rnnlm=rnnlm\n",
    "args = parser.parse_args(f'--config {decode_config} \\\n",
    "                          --ngpu 1 --backend pytorch --batchsize 1 --result-label results.json \\\n",
    "                          --model {model_path} \\\n",
    "                          {rnnlm_opts} \\\n",
    "                          --api v1')\n",
    "set_deterministic_pytorch(args)\n",
    "model.recog_args = args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "irish-jurisdiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.beam_size = 10\n",
    "args.lm_weight = 0.2\n",
    "args.ctc_weight = 0.5\n",
    "args.nbest = 1\n",
    "args.verbose = 4\n",
    "args.debugmode = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dried-increase",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files = glob(\"downloads/hindi/test/audio/*.wav\")\n",
    "audio_file = audio_files[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-microwave",
   "metadata": {},
   "source": [
    "# Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "associate-budget",
   "metadata": {},
   "outputs": [],
   "source": [
    "(signal, rate) = torchaudio.load(audio_file)\n",
    "current_signal = resampy.resample(signal[0].numpy(), rate, 8000, axis=0)\n",
    "lmspc = torchaudio.compliance.kaldi.fbank(\n",
    "            waveform=torch.unsqueeze(torch.tensor(current_signal), axis=0),\n",
    "            sample_frequency=8000,\n",
    "            dither=1e-32,\n",
    "            energy_floor=0,\n",
    "            num_mel_bins=80,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-universe",
   "metadata": {},
   "source": [
    "# Apply CMVN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sublime-survival",
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_feats = cmvn(lmspc)\n",
    "normed_feats = torch.from_numpy(normed_feats.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-english",
   "metadata": {},
   "source": [
    "# Perform inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "duplicate-patio",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    feat = (\n",
    "    [normed_feats]\n",
    "    )\n",
    "    nbest_hyps = model.recognize_batch(feat, args, char_list=train_args.char_list, rnnlm=rnnlm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-partner",
   "metadata": {},
   "source": [
    "# Print hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "collective-lesbian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HYPO for downloads/hindi/test/audio/4602_088.wav:  <eos>▁सेठ▁जी▁ने▁समझ▁लिया▁कि▁इस▁समय▁समझाने▁बुझाने▁से▁कुछ▁काम▁न▁चलेगा<eos>\n"
     ]
    }
   ],
   "source": [
    "hypothesis = ''.join([train_args.char_list[ele] for ele in nbest_hyps[0][0]['yseq']])\n",
    "print(f'HYPO for {audio_file}: ', hypothesis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
